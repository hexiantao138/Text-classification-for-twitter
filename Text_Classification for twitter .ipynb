{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library include and download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hexiantao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/hexiantao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_file(path_file):\n",
    "    with open(path_file,'r') as file_input:\n",
    "        csv_reader=csv.reader(file_input, delimiter=',')\n",
    "        next(csv_reader)\n",
    "        x_list=[]\n",
    "        y_list=[]\n",
    "        for row in csv_reader:\n",
    "            x_list.append(row[2])\n",
    "            y_list.append(row[1])\n",
    "    return x_list, y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(x_list):\n",
    "    porter_stemmer=PorterStemmer()\n",
    "    x_list_new=[]\n",
    "    for x in x_list:\n",
    "        # Lower canse#\n",
    "        x=x.lower()\n",
    "        # tokenize #\n",
    "        x_token_list=word_tokenize(x)\n",
    "        # remove stopwords #\n",
    "        x_token_list=[token for token in x_token_list if token not in stopwords.words('english')]\n",
    "        # stemming #\n",
    "        x_token_list=[porter_stemmer.stem(token) for token in x_token_list]\n",
    "        \n",
    "        x_new=''.join(x_token_list)\n",
    "        x_list_new.append(x_new)   \n",
    "    return x_list_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    path_train=('desktop/train.csv')\n",
    "    path_test=('desktop/test.csv')\n",
    "    X_train,y_train=get_data_from_file(path_train)\n",
    "    X_test,y_test=get_data_from_file(path_test)\n",
    "    X_train=text_process(X_train)\n",
    "    X_test=text_process(X_test)\n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The main structure \n",
    "## Important\n",
    "## X_train,y_train,X_test,y_test=preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from numpy import argmax, argsort, array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_binary(sample_list):\n",
    "    Vectorizer=CountVectorizer()\n",
    "    # data matrix\n",
    "    data=Vectorizer.fit_transform(sample_list).todense()\n",
    "    data[data>0]=1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the main structure\n",
    "## important\n",
    "## result=get_feature_binary(X_train)\n",
    "## result_test=get_feature_binary(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_NaiveBayesian(x,y,X_test):\n",
    "    # train\n",
    "    nbayes=MultinomialNB()\n",
    "    nbayes.fit(x,y)\n",
    "    # test\n",
    "    y_predict=nbayes.predict(X_test)\n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_Logistic(x,y,X_test):\n",
    "    # train\n",
    "    logistic=LogisticRegression()\n",
    "    logistic.fit(x,y)\n",
    "    # test\n",
    "    y_predict=logistic.predict(X_test)\n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_SVM(x,y,X_test):\n",
    "      # train\n",
    "    SVM=SVC()\n",
    "    SVM.fit(x,y)\n",
    "    # test\n",
    "    y_predict=SVM.predict(X_test)\n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(y_pred,y_test):\n",
    "    print(classification_report(y_pred,y_test,target_names=['not racist/sexist','racist/sexist'],digits=3)) # how accuracy you want to know\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayes model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## main structure ##\n",
    "X_train,y_train,X_test,y_test=preprocess()\n",
    "result=get_feature_binary(X_train+X_test)\n",
    "X_train=result[:len(X_train)]\n",
    "X_test=result[len(X_train):]\n",
    "y_predict=classify_NaiveBayesian(X_train,y_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "not racist/sexist      0.880     0.963     0.920       435\n",
      "    racist/sexist      0.333     0.123     0.180        65\n",
      "\n",
      "        micro avg      0.854     0.854     0.854       500\n",
      "        macro avg      0.607     0.543     0.550       500\n",
      "     weighted avg      0.809     0.854     0.824       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(y_predict,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## main structure ##\n",
    "X_train,y_train,X_test,y_test=preprocess()\n",
    "result=get_feature_binary(X_train+X_test)\n",
    "X_train=result[:len(X_train)]\n",
    "X_test=result[len(X_train):]\n",
    "y_predict=classify_Logistic(X_train,y_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "not racist/sexist      1.000     0.954     0.976       499\n",
      "    racist/sexist      0.042     1.000     0.080         1\n",
      "\n",
      "        micro avg      0.954     0.954     0.954       500\n",
      "        macro avg      0.521     0.977     0.528       500\n",
      "     weighted avg      0.998     0.954     0.975       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(y_predict,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## main structure ##\n",
    "X_train,y_train,X_test,y_test=preprocess()\n",
    "result=get_feature_binary(X_train+X_test)\n",
    "X_train=result[:len(X_train)]\n",
    "X_test=result[len(X_train):]\n",
    "y_predict=classify_SVM(X_train,y_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "not racist/sexist      1.000     0.952     0.975       500\n",
      "    racist/sexist      0.000     0.000     0.000         0\n",
      "\n",
      "        micro avg      0.952     0.952     0.952       500\n",
      "        macro avg      0.500     0.476     0.488       500\n",
      "     weighted avg      1.000     0.952     0.975       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "evaluation(y_predict,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
